{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b8f8e2-e1ed-43b5-8da0-deb433e76c46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "from ray import tune\n",
    "from ray import serve\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "from ray.train.xgboost import XGBoostPredictor\n",
    "from ray.train.batch_predictor import BatchPredictor\n",
    "from ray.serve import PredictorDeployment\n",
    "from ray.serve.http_adapters import pandas_read_json\n",
    "from ray.tune import Tuner, TuneConfig\n",
    "\n",
    "import requests\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5d3cba-e02a-4b85-aed0-d4d3a335d3e9",
   "metadata": {},
   "source": [
    "# Ray Train\n",
    "\n",
    "## Intro\n",
    "\n",
    "### Outline\n",
    "\n",
    "-   Goals\n",
    "-   Trainer\n",
    "    - Design\n",
    "    - Flavors\n",
    "    - In-depth with TensorFlow Trainer\n",
    "\n",
    "### Example scenario: [ TBD ]\n",
    "\n",
    "For our example use case...\n",
    "\n",
    "### Context: Ray AIR\n",
    "\n",
    "Ray AIR is the Ray AI Runtime, a set of high-level easy-to-use APIs for\n",
    "ingesting data, training models – including reinforcement learning\n",
    "models – tuning those models and then serving them.\n",
    "\n",
    "<img src=\"https://technical-training-assets.s3.us-west-2.amazonaws.com/Introduction_to_Ray_AIR/e2e_air.png\" width=600 loading=\"lazy\"/>\n",
    "\n",
    "Key principles behind Ray and Ray AIR are\n",
    "* Performance\n",
    "* Developer experience and simplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aa6a9b-e702-45d2-b59a-75609738077c",
   "metadata": {},
   "source": [
    "__Read, preprocess with Ray Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9351ec6-88cc-4ab1-ae1b-ed025d9046bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = ray.data.read_parquet(\"s3://anyscale-training-data/intro-to-ray-air/nyc_taxi_2021.parquet\")\n",
    "\n",
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffefcdb9-360b-4244-828a-8a49adb6a8a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "__Fit model with Ray Train__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1291d94e-376f-423c-b624-f1f6651e4dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = XGBoostTrainer(\n",
    "    label_column=\"is_big_tip\",\n",
    "    scaling_config=ScalingConfig(num_workers=2, use_gpu=False),\n",
    "    params={ \"objective\": \"binary:logistic\", },\n",
    "    datasets={\"train\": train_dataset, \"valid\": valid_dataset},\n",
    ")\n",
    "\n",
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6126df-8f78-4b4d-a955-a12b0b96d371",
   "metadata": {},
   "source": [
    "__Optimize hyperparams with Ray Tune__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fb7f4f-d803-40ee-8e7d-6655a396f950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = Tuner(trainer, \n",
    "            param_space={'params' : {'max_depth': tune.randint(2, 4)}},\n",
    "            tune_config=TuneConfig(num_samples=2, metric='train-logloss', mode='min'))\n",
    "\n",
    "checkpoint = tuner.fit().get_best_result().checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e681533b-0df1-45c9-81bc-74e40ce076d8",
   "metadata": {},
   "source": [
    "__Batch prediction__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d33dc-d7d2-4a7f-b309-0b7aac030994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_predictor = BatchPredictor.from_checkpoint(checkpoint, XGBoostPredictor)\n",
    "\n",
    "predicted_probabilities = batch_predictor.predict(valid_dataset.drop_columns(['is_big_tip']))\n",
    "predicted_probabilities.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d66b61a-f001-483c-846c-02b5f8c06acc",
   "metadata": {},
   "source": [
    "__Online prediction with Ray Serve__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af460fe-18f9-4af0-8301-9d00ca00bca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deployment = PredictorDeployment.bind(XGBoostPredictor, result.checkpoint, http_adapter=pandas_read_json)\n",
    "\n",
    "serve.run(deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592bab94-4fd1-41fc-a038-f77669d15922",
   "metadata": {},
   "source": [
    "__HTTP or Python services__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05578ff7-161b-4e5a-b825-18ceba9393f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_input = dict(valid_dataset.take(1)[0])\n",
    "del(sample_input['is_big_tip'])\n",
    "del(sample_input['__index_level_0__'])\n",
    "requests.post(\"http://localhost:8000/\", json=[sample_input]).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec926284-e57d-4ac8-a2ce-151e0e153dce",
   "metadata": {},
   "source": [
    "## Train Goals\n",
    "\n",
    "* Developer experience\n",
    "* Flexibility\n",
    "* Performance and simplicity via delegation\n",
    "    * Train does not re-implement distributed optimizers\n",
    "    * Train coordinates and delegates native platform distributed training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71b7829-aa50-45ee-8f5c-123d09d17572",
   "metadata": {},
   "source": [
    "## `Trainer` design and usage\n",
    "\n",
    "### Idea: Trainer -> Checkpoint\n",
    "   \n",
    "* Trainer used by Train, Tune\n",
    "* Checkpoint used for inference (Ray Data [batch], Serve [online]) and reporting\n",
    "\n",
    "### Trainer Flavors\n",
    "\n",
    "* Tree - e.g., XGBoost\n",
    "* Library - e.g., Huggingface\n",
    "* DL Trainers\n",
    "    * PyTorch, TensorFlow, Horovod, Lightning, Accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d515f2f-7e53-424e-a010-8e290e51e27f",
   "metadata": {},
   "source": [
    "### Focus: Tensorflow Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85894e8-86b3-46b0-a8ef-897ceadaf400",
   "metadata": {},
   "source": [
    "\"Hello World\" (iris) example with minimal model to look at data/train structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead525b-ea0a-4982-bfd2-ef513abdd0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from ray.air import session\n",
    "from ray.air.integrations.keras import ReportCheckpointCallback\n",
    "from ray.train.tensorflow import TensorflowTrainer\n",
    "from ray.air.config import ScalingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a093b-83df-4a6b-bb25-59e4f95bd87c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "ds = ray.data.read_csv(\"s3://air-example-data/iris.csv\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb72a71-998e-4db2-9eb6-db7fd4f8c7e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray.data.preprocessors import Concatenator\n",
    "\n",
    "preprocessor = Concatenator(output_column_name=\"features\", exclude=\"target\")\n",
    "\n",
    "ds = preprocessor.transform(ds)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d2b2e-3964-4a50-bef5-2c7d360a929c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model() -> tf.keras.Model:\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(4,)),\n",
    "            tf.keras.layers.Dense(5),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_func(config: dict):\n",
    "    batch_size = config.get(\"batch_size\", 64)\n",
    "    epochs = config.get(\"epochs\", 3)\n",
    "\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        # Model building/compiling need to be within `strategy.scope()`.\n",
    "        multi_worker_model = build_model()\n",
    "        multi_worker_model.compile(\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=config.get(\"lr\", 1e-3)),\n",
    "            loss=tf.keras.losses.mean_squared_error,\n",
    "            metrics=[tf.keras.metrics.mean_squared_error],\n",
    "        )\n",
    "\n",
    "    dataset = session.get_dataset_shard(\"train\")\n",
    "\n",
    "    results = []\n",
    "    for _ in range(epochs):\n",
    "        tf_dataset = dataset.to_tf(\n",
    "            feature_columns=\"features\", label_columns=\"target\", batch_size=batch_size\n",
    "        )\n",
    "        history = multi_worker_model.fit(\n",
    "            tf_dataset, callbacks=[ReportCheckpointCallback()]\n",
    "        )\n",
    "        results.append(history.history)\n",
    "    return results\n",
    "\n",
    "\n",
    "train_config = {\"lr\": 1e-3, \"batch_size\": 32, \"epochs\": 4}\n",
    "\n",
    "scaling_config = ScalingConfig(num_workers=2, use_gpu=False)\n",
    "\n",
    "trainer = TensorflowTrainer(\n",
    "    train_loop_per_worker=train_func,\n",
    "    train_loop_config=train_config,\n",
    "    scaling_config=scaling_config,\n",
    "    datasets={\"train\": ds},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5bc5bb-12e5-41cd-87b1-4028841ec3dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad20af9-34e5-41c5-a420-424171d15865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(result.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a689919-2ae0-4ae9-8a60-48c52ca3c5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b4f7f-cc2e-4052-a28a-1e1be5f1b0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50f048-8304-4249-9c0a-b53a4960bd59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71afeb9b-1938-4dc8-8b57-6804365c9dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "648f1aad-5d8c-4ac2-b652-abbdb391b83e",
   "metadata": {},
   "source": [
    "MNIST example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7a87ac-a41b-4bd3-95e8-e89ddb1fa218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from filelock import FileLock\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835698c4-f755-452b-85ec-02f97bfe60b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mnist_dataset(batch_size: int) -> tf.data.Dataset:\n",
    "    with FileLock(os.path.expanduser(\"~/.mnist_lock\")):\n",
    "        (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "    # The `x` arrays are in uint8 and have values in the [0, 255] range.\n",
    "    # You need to convert them to float32 with values in the [0, 1] range.\n",
    "    x_train = x_train / np.float32(255)\n",
    "    y_train = y_train.astype(np.int64)\n",
    "    train_dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "        .shuffle(60000)\n",
    "        .repeat()\n",
    "        .batch(batch_size)\n",
    "    )\n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f65c19-2932-48da-86c4-1cc52376b8ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_cnn_model() -> tf.keras.Model:\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(28, 28)),\n",
    "            tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d559fbe-bac4-435a-9279-7a6caf52003d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_func(config: dict):\n",
    "    per_worker_batch_size = config.get(\"batch_size\", 64)\n",
    "    epochs = config.get(\"epochs\", 3)\n",
    "    steps_per_epoch = config.get(\"steps_per_epoch\", 70)\n",
    "\n",
    "    tf_config = json.loads(os.environ[\"TF_CONFIG\"])\n",
    "    num_workers = len(tf_config[\"cluster\"][\"worker\"])\n",
    "\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "    global_batch_size = per_worker_batch_size * num_workers\n",
    "    multi_worker_dataset = mnist_dataset(global_batch_size)\n",
    "\n",
    "    with strategy.scope():\n",
    "        # Model building/compiling need to be within `strategy.scope()`.\n",
    "        multi_worker_model = build_cnn_model()\n",
    "        learning_rate = config.get(\"lr\", 0.001)\n",
    "        multi_worker_model.compile(\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "    history = multi_worker_model.fit(\n",
    "        multi_worker_dataset,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        callbacks=[ReportCheckpointCallback()],\n",
    "    )\n",
    "    results = history.history\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada1d7b-398e-486f-91ff-2213b5c36dba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\"lr\": 1e-3, \"batch_size\": 64, \"epochs\": 3}\n",
    "\n",
    "trainer = TensorflowTrainer(\n",
    "    train_loop_per_worker=train_func,\n",
    "    train_loop_config=config,\n",
    "    scaling_config=ScalingConfig(num_workers=2, use_gpu=False),\n",
    ")\n",
    "\n",
    "results = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1e82c-44a2-4254-a2ad-c7f1df327ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc0d3ee-ad9f-4fa0-a435-26813611f6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
